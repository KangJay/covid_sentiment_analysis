{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "further-chemistry",
   "metadata": {},
   "source": [
    "# Utilizing Twitter to Measure the Public's Sentiment on the Pandemic Over Time\n",
    "**Team 7:** Insert Name Here \n",
    "\n",
    "**Members:** Lipsa J., Ji K., Yuanfeng L., Yu L."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graphic-moscow",
   "metadata": {},
   "source": [
    "The pandemic has uprooted the lives of every single person in the world. While it began as a minor inconvenience to many people, the harsh reality and severity of the virus were soon realized. In the beginning of enforcing protective measures to protect the public, many people's opinions on the virus, protective rules & procedures, and other topics relating to the pandemic have changed and continually do into 2021. We want to record and analyze these trends by looking at the metrics such as sentiment, LIWC metrics, and possibly more as we make further discoveries.\n",
    "\n",
    "Utilizing Twitter, an online social media platform for sharing content and microblogging, we'll be analyzing \"tweets\" (publically posted messages) from everyday people about how they feel about the pandemic. This procedure will be run on data from January 22 2020, all the way to the most current data being available at this current time of the project (February and March of 2021). \n",
    "\n",
    "We've outlined objectives & research questions we hope to answer through this approach.\n",
    "* **Goal 1**: Find out how many tweets sentiments changed on the regulation or rules about wearing a mask or taking a vaccine for the the year 2020 and current months in 2021 (January - March)\n",
    "* **Goal 2**: Find out the sentiment of tweets relating to the COVID-19 virus for the year 2020 and the current months in 2021 (January - March)\n",
    "* **Stretch Goal 1**: Find out the sentiments across geographical locations within the U.S about either protective measures (Eg. Wearing a mask) and the taking the vaccine. It's been shown throughout various news outlets and social media that different areas in the U.S have had varying responses to these rules. If time & resources allow, we want to run the research experiment at a lower level - focusing on specific areas in the U.S - Perhaps areas with the lowest cases per capita vs. moderate vs. high. \n",
    "* **Stretch goal 2**: Relate our findings to how misinformation & fake news on Twitter changed before and after the election; as well as its possible consequences on the public's sentiment on the topic of COVID-19 and its related topics (Eg. vaccines, lockdown, social distancing).\n",
    "\n",
    "Through our efforts, we hope to be able to answer or at least find insight into the following questions as well:\n",
    "* Have specific events affected the public's stance on the pandemic? These could be the presidential election, the presidential candidates debate as well as the vice-presidents debate, Trump getting diagnosed and hospital stayed, and so on. \n",
    "* How have different cities, counties, and states efficacy in containing the virus relate to the public sentiment from the people there?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foreign-bunch",
   "metadata": {},
   "source": [
    "## Our Current Approach\n",
    "Currently, we're utilizing Twitter for our data generation. Initially, we stated that we'd be utilizing Reddit as well but the caveats of a public forum platform is that it's heavily moderated. With the pandemic being a global crisis, Reddit has emphasized initiatives to remove and censor posts that may be incediary, controversial, promote misinformation and so on. While these things are negative in the grand scheme of society, we actually want to collect this kind of data as well since it shows a sub-population with different views. \n",
    "\n",
    "We're utilizing Tweepy which is Twitter's API wrapper for Python. It's extremely easy to utilize but one of its caveats is that it will only look at the past week to pull data; which makes sense since many people actually use real-time data for analysis. To get around this issue, we relied on Kaggle and IEEE.\n",
    "Both of them have been data mining the ID number of tweets with keywords relating to the pandemic since near the beginning of 2020. These keywords include identifiers such as \"n95\", \"ppe\", \"washyourhands\", \"stayathome\", \"selfisolating\", \"social distancing\", \"covid-19\", and so on. \n",
    "\n",
    "Utilizing Tweepy and Python, we iterate through these tweet id values to pull the actual tweet status object from Twitter. From there, we extract the following information: \n",
    "* id: ID number of the tweet\n",
    "* username: Username of the person who posted the tweet\n",
    "* text: The literal text content of the tweet\n",
    "* entities: Hashtags the tweet had\n",
    "* retweet_count: Number of times the tweet had been retweeted\n",
    "* favorite_count: Number of times the tweet had been favorited\n",
    "* created_at: Time the tweet had been posted\n",
    "\n",
    "We're collecting our own data currently with the same parameters and keywords. Taking these datasets, in a csv format, we're running each through LIWC and looking at the following metrics: \n",
    "* Summary variables: Analytical thinking, clout, authentic, and emotional tone\n",
    "* Affect words: Positive emotions, negative emotions, anxiety, anger, sadness\n",
    "* Social words: Family, friends, female referents, male referents\n",
    "* Cognitive Processes: Insight\n",
    "* Biological processes: Body, health/illness\n",
    "* Personal concerns: Work, leisure, money\n",
    "* Informal speech: Swear words\n",
    "\n",
    "While the biggest contributors will be relating to authenticity, emotions (emotional tone & positive/negative emotions), we believe the other attributes will aid answering in our research questions and stretch goals.\n",
    "\n",
    "## Collecting Twitter Data From the Entirety of 2020\n",
    "As mentioned previously, since we can only directly scrape tweets for the past week, we utilize Kaggle's dataset which is found at https://www.kaggle.com/lopezbec/covid19-tweets-dataset.\n",
    "\n",
    "Additionally, the IEEE have published a similar dataset with a wider range of keywords which can be found at https://ieee-dataport.org/open-access/coronavirus-covid-19-tweets-dataset. \n",
    "\n",
    "These files contain minimal data in order to save space. Kaggle's has just the tweet ids in a list-like structure, while the IEEE has a similar format but in pairs of tweet id and a sentiment score calculated for the content of the tweet. \n",
    "\n",
    "A snippet of the dataset content: \n",
    "[1220041022694137856, 1220041024031977472, 1220041026661965824, 1220041030478761984, 1220041036107370496, 1220041039597015040, 1220041040012480513, 1220041041971118080, 1220041046484082689, 1220041052641325056]\n",
    "\n",
    "This is a very small portion from one day. Every one of those numbers refers to a tweet. Each day has more than 80,000 tweets worth of tweet ids - which for the scope of the project, we feel is very \"overkill\". Since we're looking at the entire year, this results in hundreds of gigabytes of actual twitter data. We sampled from these files and utilized Tweepy to collect the twitter status objects to extract data from. \n",
    "\n",
    "From the descriptions of both platforms, they have collected the data utilizing keyword searching only which is what we're doing as well. From this assumption, we utilize the tweet-id dataset as to represent the tweet data as if we manually ran Tweepy from the beginning of 2020 to 2021. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "restricted-chapter",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, json, time, tweepy\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "\"\"\"\n",
    "Looks in the current directory for Twitter developer credential files in a json\n",
    "Loads up the appropriate key-value pairings and returns it. \n",
    "\"\"\"\n",
    "def load_keys(key_file):\n",
    "    with open(key_file) as f:\n",
    "        key_dict = json.load(f)\n",
    "    return key_dict['api_key'], key_dict['api_secret'], key_dict['token'], key_dict['token_secret']\n",
    "\n",
    "\"\"\"\n",
    "Helper method for recursive descent into each directory. The data files are often separated by month, \n",
    "then individual files represent the tweet id values collected for that day. \n",
    "\"\"\"\n",
    "def get_path():\n",
    "    iterate_files(os.getcwd(), \"\")\n",
    "\n",
    "\"\"\"\n",
    "path = absolute path of the files.\n",
    "subdir = current path in respect to the home directory of the folder.\n",
    "\"\"\"\n",
    "def iterate_files(path, subdir):\n",
    "    #Load credentials\n",
    "    KEY_FILE = \"./twitter.json\"\n",
    "    api_key, api_secret, token, token_secret = load_keys(KEY_FILE)\n",
    "    \n",
    "    auth = tweepy.OAuthHandler(api_key, api_secret)\n",
    "    auth.set_access_token(token, token_secret)\n",
    "    api = tweepy.API(auth)\n",
    "    \n",
    "    # File recursion portion. Irrelevant to actual data collection.\n",
    "    # Author: Ji-Hoon. Wrote this recursive directory program for a file-backup program. Repurposed for this project.\n",
    "    for filename in os.listdir(path):\n",
    "        filePath = path + \"/\" + filename\n",
    "        if (os.path.isdir(filePath)):\n",
    "            tempSubdir = \"\"\n",
    "            if subdir: tempSubdir = subdir + \"/\" + filename\n",
    "            else: tempSubdir = filename\n",
    "            iterate_files(filePath, tempSubdir)\n",
    "        else:\n",
    "            filekey = subdir\n",
    "            if subdir: file = subdir + \"/\" + filename\n",
    "            else: file = filename\n",
    "            tweet_content = defaultdict(list)\n",
    "            \n",
    "            if filename != 'process_tweets.py': # The python program will attempt to read in itself.\n",
    "                tweet_ids = open(filePath, 'r')\n",
    "                content = tweet_ids.read()[1:-1] #removes beginning and ending '[' and  ']'\n",
    "                \n",
    "                #Each id value is comma separated \n",
    "                ids = np.fromstring(content, dtype=int, sep= ',')\n",
    "                \n",
    "                tweet = None\n",
    "                for id in ids: # Each tweet id\n",
    "                    try:\n",
    "                        tweet = api.get_status(id) #returns status object\n",
    "                    except tweepy.RateLimitError:\n",
    "                        # Rate limit is 15,000 requests per 15 minutes.\n",
    "                        print(\"Rate Limit hit. Sleeping for 15 minutes.\")\n",
    "                        time.sleep(900)\n",
    "                        continue\n",
    "                        # Treats suspended users as a 404 request. Their actual page is deleted so the content has been as well.\n",
    "                    except Exception as e:\n",
    "                        # Suspended/Deleted users don't contribute any data so we skip them. \n",
    "                        continue\n",
    "                    if tweet is None:\n",
    "                        print(\"Should never be reached. If seen, something went wrong.\")\n",
    "                    # Extract the features listed prior, convert to a data frame, then save to a uniquely named csv file.\n",
    "                    tweet_content['id'].append(tweet.id)\n",
    "                    tweet_content['username'].append(tweet.user.name)\n",
    "                    tweet_content['text'].append(tweet.text)\n",
    "                    tweet_content['entities'].append(tweet.entities)\n",
    "                    tweet_content['retweet_count'].append(tweet.retweet_count)\n",
    "                    tweet_content['favorite_count'].append(tweet.favorite_count)\n",
    "                    tweet_content['created_at'].append(tweet.created_at)\n",
    "                pd.DataFrame(tweet_content).to_csv(filename[:-4] + \".csv\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    get_path()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adult-budget",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "retired-fluid",
   "metadata": {},
   "source": [
    "## Current Data Collection in 2021\n",
    "We relied on those datasets to help supplement the earlier twitter data we can't directly retrieve. However, for the current data, we're querying and data mining with a similar approach. \n",
    "\n",
    "We have taken inspiration from the IEEE Coronavirus (COVID-19) Tweets Dataset, which can be found at https://ieee-dataport.org/open-access/coronavirus-covid-19-tweets-dataset. They have collected tweets relating to a large set of keywords since the very beginning of the pandemic and continually do so. We have taken a scaled down version and taken specific keywords from their larger set - which can be found at https://rlamsal.com.np/keywords.tsv. Note: The link will start the download of a tab-separated file with the keywords but is small in terms of memory size. Just a warning.\n",
    "\n",
    "We data mined data in the same fashion, ran the text fields through LIWC, and separated files to organize based on the time period they represent. A snippet of the outputted file can be shown here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "racial-comparative",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   standard            id            username  \\\n",
      "0         0  1.363275e+18        Fire Is Born   \n",
      "1         1  1.363263e+18   MyFrenchDietitian   \n",
      "2         2  1.363260e+18  healingcolorsmusic   \n",
      "3         3  1.363260e+18  healingcolorsmusic   \n",
      "4         4  1.363260e+18  healingcolorsmusic   \n",
      "\n",
      "                                                text  \\\n",
      "0  @iamungit I've been in one of them in San Fran...   \n",
      "1  Enjoy the #weekend, go #outdoor, reconnect wit...   \n",
      "2  #healingcolorsmusic #art #music ...there is #S...   \n",
      "3  #healingcolorsmusic #art #music ...there is #S...   \n",
      "4  #healingcolorsmusic #art #music ...there is #S...   \n",
      "\n",
      "                                            entities retweet_count  \\\n",
      "0  {'hashtags': [{'text': 'WearMask', 'indices': ...             1   \n",
      "1  {'hashtags': [{'text': 'weekend', 'indices': [...             0   \n",
      "2  {'hashtags': [{'text': 'healingcolorsmusic', '...             0   \n",
      "3  {'hashtags': [{'text': 'healingcolorsmusic', '...             0   \n",
      "4  {'hashtags': [{'text': 'healingcolorsmusic', '...             0   \n",
      "\n",
      "  favorite_count           created_at  WC Analytic  ... Quote Apostro Parenth  \\\n",
      "0              1  2021-02-20 23:52:00  25    93.26  ...   0.0     4.0     0.0   \n",
      "1              1  2021-02-20 23:01:59  24    93.26  ...   0.0     0.0     0.0   \n",
      "2              1  2021-02-20 22:52:27  19    93.26  ...   0.0     0.0     0.0   \n",
      "3              1  2021-02-20 22:50:59  19    93.26  ...   0.0     0.0     0.0   \n",
      "4              1  2021-02-20 22:49:58  19    93.26  ...   0.0     0.0     0.0   \n",
      "\n",
      "  OtherP  Unnamed: 101  Unnamed: 102  Unnamed: 103  Unnamed: 104  \\\n",
      "0  16.00           NaN           NaN           NaN           NaN   \n",
      "1  29.17           NaN           NaN           NaN           NaN   \n",
      "2  52.63           NaN           NaN           NaN           NaN   \n",
      "3  52.63           NaN           NaN           NaN           NaN   \n",
      "4  52.63           NaN           NaN           NaN           NaN   \n",
      "\n",
      "   Unnamed: 105  Unnamed: 106  \n",
      "0           NaN           NaN  \n",
      "1           NaN           NaN  \n",
      "2           NaN           NaN  \n",
      "3           NaN           NaN  \n",
      "4           NaN           NaN  \n",
      "\n",
      "[5 rows x 107 columns]\n",
      "Column Names: ['standard', 'id', 'username', 'text', 'entities', 'retweet_count', 'favorite_count', 'created_at', 'WC', 'Analytic', 'Clout', 'Authentic', 'Tone', 'WPS', 'Sixltr', 'Dic', 'function', 'pronoun', 'ppron', 'i', 'we', 'you', 'shehe', 'they', 'ipron', 'article', 'prep', 'auxverb', 'adverb', 'conj', 'negate', 'verb', 'adj', 'compare', 'interrog', 'number', 'quant', 'affect', 'posemo', 'negemo', 'anx', 'anger', 'sad', 'social', 'family', 'friend', 'female', 'male', 'cogproc', 'insight', 'cause', 'discrep', 'tentat', 'certain', 'differ', 'percept', 'see', 'hear', 'feel', 'bio', 'body', 'health', 'sexual', 'ingest', 'drives', 'affiliation', 'achieve', 'power', 'reward', 'risk', 'focuspast', 'focuspresent', 'focusfuture', 'relativ', 'motion', 'space', 'time', 'work', 'leisure', 'home', 'money', 'relig', 'death', 'informal', 'swear', 'netspeak', 'assent', 'nonflu', 'filler', 'AllPunc', 'Period', 'Comma', 'Colon', 'SemiC', 'QMark', 'Exclam', 'Dash', 'Quote', 'Apostro', 'Parenth', 'OtherP', 'Unnamed: 101', 'Unnamed: 102', 'Unnamed: 103', 'Unnamed: 104', 'Unnamed: 105', 'Unnamed: 106']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "sample = pd.read_csv('LIWC2015_feb.csv')\n",
    "print(sample.head())\n",
    "\n",
    "print(\"Column Names: {}\".format(list(sample.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cosmetic-canada",
   "metadata": {},
   "source": [
    "We have noticed some problems across different operating systems for handling csv files. We initially ran into problems while sharing datasets with each other across Debian, Windows, and Mac and have resolved most of them since. One example is that some empty columns will show themselves as \"Unnamed\" columns with empty or NaN values in them. We ignore these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dress-saver",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>standard</th>\n",
       "      <th>id</th>\n",
       "      <th>username</th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>created_at</th>\n",
       "      <th>WC</th>\n",
       "      <th>Analytic</th>\n",
       "      <th>...</th>\n",
       "      <th>Quote</th>\n",
       "      <th>Apostro</th>\n",
       "      <th>Parenth</th>\n",
       "      <th>OtherP</th>\n",
       "      <th>Unnamed: 101</th>\n",
       "      <th>Unnamed: 102</th>\n",
       "      <th>Unnamed: 103</th>\n",
       "      <th>Unnamed: 104</th>\n",
       "      <th>Unnamed: 105</th>\n",
       "      <th>Unnamed: 106</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15037</th>\n",
       "      <td>40342</td>\n",
       "      <td>1.363335e+18</td>\n",
       "      <td>King Jamison Fawkes ♚</td>\n",
       "      <td>@WildHogPower \"WELL WELL WELL WELL WELL WELL W...</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-02-21 03:50:29</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15994</th>\n",
       "      <td>43474</td>\n",
       "      <td>1.363335e+18</td>\n",
       "      <td>King Jamison Fawkes ♚</td>\n",
       "      <td>@WildHogPower \"WELL WELL WELL WELL WELL WELL W...</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-02-21 03:50:29</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9187</th>\n",
       "      <td>21521</td>\n",
       "      <td>1.363309e+18</td>\n",
       "      <td>FA_eye(formally Accureye) #CyberPunk2077</td>\n",
       "      <td>@TheSphereHunter Nice love it great mask</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-02-21 02:05:49</td>\n",
       "      <td>6</td>\n",
       "      <td>62.04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12488</th>\n",
       "      <td>32070</td>\n",
       "      <td>1.363325e+18</td>\n",
       "      <td>TEA POt</td>\n",
       "      <td>@FailedSoul_ *winning laughs* pretty impressiv...</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-02-21 03:10:45</td>\n",
       "      <td>8</td>\n",
       "      <td>72.69</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14506</th>\n",
       "      <td>38373</td>\n",
       "      <td>1.363325e+18</td>\n",
       "      <td>TEA POt</td>\n",
       "      <td>@FailedSoul_ *winning laughs* pretty impressiv...</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-02-21 03:10:45</td>\n",
       "      <td>8</td>\n",
       "      <td>72.69</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17703</th>\n",
       "      <td>50702</td>\n",
       "      <td>1.363353e+18</td>\n",
       "      <td>Mask Up 2021</td>\n",
       "      <td>@lindyli That's helpful. Thanks.</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-02-21 05:02:38</td>\n",
       "      <td>4</td>\n",
       "      <td>1.92</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5789</th>\n",
       "      <td>11080</td>\n",
       "      <td>1.363292e+18</td>\n",
       "      <td>T Partain</td>\n",
       "      <td>@Kiss_My_Mask Works pretty good unstoppiunstop...</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-02-21 00:57:26</td>\n",
       "      <td>7</td>\n",
       "      <td>68.29</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1712</th>\n",
       "      <td>1712</td>\n",
       "      <td>1.363270e+18</td>\n",
       "      <td>Dirk Diggler MMA🥊👊🏿😈</td>\n",
       "      <td>@Delta Lol nice mask pussy</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-02-20 23:30:29</td>\n",
       "      <td>5</td>\n",
       "      <td>93.26</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7553</th>\n",
       "      <td>16307</td>\n",
       "      <td>1.363300e+18</td>\n",
       "      <td>Keri Casazza</td>\n",
       "      <td>@heavenskincare Would love to win, I'm loving ...</td>\n",
       "      <td>{'hashtags': [{'text': 'win', 'indices': [66, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-02-21 01:32:21</td>\n",
       "      <td>13</td>\n",
       "      <td>43.96</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>1122</td>\n",
       "      <td>1.363273e+18</td>\n",
       "      <td>dave@az</td>\n",
       "      <td>@PissOffTrumpkin Good afternoon.  Love the mask.</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-02-20 23:44:56</td>\n",
       "      <td>6</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       standard            id                                  username  \\\n",
       "15037     40342  1.363335e+18                     King Jamison Fawkes ♚   \n",
       "15994     43474  1.363335e+18                     King Jamison Fawkes ♚   \n",
       "9187      21521  1.363309e+18  FA_eye(formally Accureye) #CyberPunk2077   \n",
       "12488     32070  1.363325e+18                                   TEA POt   \n",
       "14506     38373  1.363325e+18                                   TEA POt   \n",
       "17703     50702  1.363353e+18                              Mask Up 2021   \n",
       "5789      11080  1.363292e+18                                 T Partain   \n",
       "1712       1712  1.363270e+18                      Dirk Diggler MMA🥊👊🏿😈   \n",
       "7553      16307  1.363300e+18                              Keri Casazza   \n",
       "1122       1122  1.363273e+18                                   dave@az   \n",
       "\n",
       "                                                    text  \\\n",
       "15037  @WildHogPower \"WELL WELL WELL WELL WELL WELL W...   \n",
       "15994  @WildHogPower \"WELL WELL WELL WELL WELL WELL W...   \n",
       "9187            @TheSphereHunter Nice love it great mask   \n",
       "12488  @FailedSoul_ *winning laughs* pretty impressiv...   \n",
       "14506  @FailedSoul_ *winning laughs* pretty impressiv...   \n",
       "17703                   @lindyli That's helpful. Thanks.   \n",
       "5789   @Kiss_My_Mask Works pretty good unstoppiunstop...   \n",
       "1712                          @Delta Lol nice mask pussy   \n",
       "7553   @heavenskincare Would love to win, I'm loving ...   \n",
       "1122    @PissOffTrumpkin Good afternoon.  Love the mask.   \n",
       "\n",
       "                                                entities retweet_count  \\\n",
       "15037  {'hashtags': [], 'symbols': [], 'user_mentions...             0   \n",
       "15994  {'hashtags': [], 'symbols': [], 'user_mentions...             0   \n",
       "9187   {'hashtags': [], 'symbols': [], 'user_mentions...             0   \n",
       "12488  {'hashtags': [], 'symbols': [], 'user_mentions...             0   \n",
       "14506  {'hashtags': [], 'symbols': [], 'user_mentions...             0   \n",
       "17703  {'hashtags': [], 'symbols': [], 'user_mentions...             0   \n",
       "5789   {'hashtags': [], 'symbols': [], 'user_mentions...             0   \n",
       "1712   {'hashtags': [], 'symbols': [], 'user_mentions...             0   \n",
       "7553   {'hashtags': [{'text': 'win', 'indices': [66, ...             0   \n",
       "1122   {'hashtags': [], 'symbols': [], 'user_mentions...             0   \n",
       "\n",
       "      favorite_count           created_at  WC Analytic  ... Quote Apostro  \\\n",
       "15037              0  2021-02-21 03:50:29  26        1  ...  3.85    0.00   \n",
       "15994              1  2021-02-21 03:50:29  26        1  ...  3.85    0.00   \n",
       "9187               0  2021-02-21 02:05:49   6    62.04  ...  0.00    0.00   \n",
       "12488              0  2021-02-21 03:10:45   8    72.69  ...  0.00    0.00   \n",
       "14506              1  2021-02-21 03:10:45   8    72.69  ...  0.00    0.00   \n",
       "17703              0  2021-02-21 05:02:38   4     1.92  ...  0.00   25.00   \n",
       "5789               1  2021-02-21 00:57:26   7    68.29  ...  0.00    0.00   \n",
       "1712               0  2021-02-20 23:30:29   5    93.26  ...  0.00    0.00   \n",
       "7553               0  2021-02-21 01:32:21  13    43.96  ...  0.00    7.69   \n",
       "1122               0  2021-02-20 23:44:56   6       99  ...  0.00    0.00   \n",
       "\n",
       "      Parenth OtherP  Unnamed: 101  Unnamed: 102  Unnamed: 103  Unnamed: 104  \\\n",
       "15037     0.0  11.54           NaN           NaN           NaN           NaN   \n",
       "15994     0.0  11.54           NaN           NaN           NaN           NaN   \n",
       "9187      0.0  16.67           NaN           NaN           NaN           NaN   \n",
       "12488     0.0  50.00           NaN           NaN           NaN           NaN   \n",
       "14506     0.0  50.00           NaN           NaN           NaN           NaN   \n",
       "17703     0.0  25.00           NaN           NaN           NaN           NaN   \n",
       "5789      0.0  42.86           NaN           NaN           NaN           NaN   \n",
       "1712      0.0  20.00           NaN           NaN           NaN           NaN   \n",
       "7553      0.0  23.08           NaN           NaN           NaN           NaN   \n",
       "1122      0.0  16.67           NaN           NaN           NaN           NaN   \n",
       "\n",
       "       Unnamed: 105  Unnamed: 106  \n",
       "15037           NaN           NaN  \n",
       "15994           NaN           NaN  \n",
       "9187            NaN           NaN  \n",
       "12488           NaN           NaN  \n",
       "14506           NaN           NaN  \n",
       "17703           NaN           NaN  \n",
       "5789            NaN           NaN  \n",
       "1712            NaN           NaN  \n",
       "7553            NaN           NaN  \n",
       "1122            NaN           NaN  \n",
       "\n",
       "[10 rows x 107 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.nlargest(10, ['posemo'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technical-seeking",
   "metadata": {},
   "source": [
    "The 10 tweets from the most recently collected data that have the highest scores in terms of positive emotions. However, we noticed that even tweets that have a positive sentiment initially can that the overall message is negative. This is why the other metrics are utilized alongside. For comparison, here is the top 10 most negative tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "promotional-equivalent",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>standard</th>\n",
       "      <th>id</th>\n",
       "      <th>username</th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>created_at</th>\n",
       "      <th>WC</th>\n",
       "      <th>Analytic</th>\n",
       "      <th>...</th>\n",
       "      <th>Quote</th>\n",
       "      <th>Apostro</th>\n",
       "      <th>Parenth</th>\n",
       "      <th>OtherP</th>\n",
       "      <th>Unnamed: 101</th>\n",
       "      <th>Unnamed: 102</th>\n",
       "      <th>Unnamed: 103</th>\n",
       "      <th>Unnamed: 104</th>\n",
       "      <th>Unnamed: 105</th>\n",
       "      <th>Unnamed: 106</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12848</th>\n",
       "      <td>32430</td>\n",
       "      <td>1.363322e+18</td>\n",
       "      <td>BIG_B00B$</td>\n",
       "      <td>WEAR A FUCKING MASK YOU STUPID FUCK</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-02-21 02:59:35</td>\n",
       "      <td>7</td>\n",
       "      <td>93.26</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20535</th>\n",
       "      <td>61597</td>\n",
       "      <td>1.363367e+18</td>\n",
       "      <td>Sassy | BLM</td>\n",
       "      <td>Goodnight. Fuck racists. Fuck Ted Cuntface Cru...</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-02-21 05:58:21</td>\n",
       "      <td>11</td>\n",
       "      <td>98.34</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>235</td>\n",
       "      <td>1.360839e+18</td>\n",
       "      <td>calledryan</td>\n",
       "      <td>copernicus was wrong</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-02-14 06:30:15</td>\n",
       "      <td>3</td>\n",
       "      <td>18.82</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9540</th>\n",
       "      <td>21874</td>\n",
       "      <td>1.363307e+18</td>\n",
       "      <td>KingOfSoup ❼</td>\n",
       "      <td>My mask ugly</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-02-21 01:57:06</td>\n",
       "      <td>3</td>\n",
       "      <td>18.82</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10850</th>\n",
       "      <td>26761</td>\n",
       "      <td>1.363317e+18</td>\n",
       "      <td>President Dr.Jillian(MAGA Bean)🇺🇸</td>\n",
       "      <td>America is full of fools. Weak mask wearing fo...</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2021-02-21 02:39:01</td>\n",
       "      <td>9</td>\n",
       "      <td>93.26</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12092</th>\n",
       "      <td>29923</td>\n",
       "      <td>1.363317e+18</td>\n",
       "      <td>President Dr.Jillian(MAGA Bean)🇺🇸</td>\n",
       "      <td>America is full of fools. Weak mask wearing fo...</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2021-02-21 02:39:01</td>\n",
       "      <td>9</td>\n",
       "      <td>93.26</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17667</th>\n",
       "      <td>50666</td>\n",
       "      <td>1.363354e+18</td>\n",
       "      <td>Dean Forbes</td>\n",
       "      <td>@Coolretro72 Mask fail.</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-02-21 05:03:28</td>\n",
       "      <td>3</td>\n",
       "      <td>93.26</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21424</th>\n",
       "      <td>66013</td>\n",
       "      <td>1.363354e+18</td>\n",
       "      <td>Dean Forbes</td>\n",
       "      <td>@Coolretro72 Mask fail.</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-02-21 05:03:28</td>\n",
       "      <td>3</td>\n",
       "      <td>93.26</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9083</th>\n",
       "      <td>21417</td>\n",
       "      <td>1.363310e+18</td>\n",
       "      <td>mask is losing</td>\n",
       "      <td>Oh fuck I missed more than 1 affinity shit bet...</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-02-21 02:09:11</td>\n",
       "      <td>17</td>\n",
       "      <td>93.26</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3931</th>\n",
       "      <td>5721</td>\n",
       "      <td>1.363284e+18</td>\n",
       "      <td>Liz Harvey</td>\n",
       "      <td>Also mask to face ratio SUCKS SHIT</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2021-02-21 00:26:37</td>\n",
       "      <td>7</td>\n",
       "      <td>68.29</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       standard            id                           username  \\\n",
       "12848     32430  1.363322e+18                          BIG_B00B$   \n",
       "20535     61597  1.363367e+18                        Sassy | BLM   \n",
       "235         235  1.360839e+18                         calledryan   \n",
       "9540      21874  1.363307e+18                       KingOfSoup ❼   \n",
       "10850     26761  1.363317e+18  President Dr.Jillian(MAGA Bean)🇺🇸   \n",
       "12092     29923  1.363317e+18  President Dr.Jillian(MAGA Bean)🇺🇸   \n",
       "17667     50666  1.363354e+18                        Dean Forbes   \n",
       "21424     66013  1.363354e+18                        Dean Forbes   \n",
       "9083      21417  1.363310e+18                     mask is losing   \n",
       "3931       5721  1.363284e+18                         Liz Harvey   \n",
       "\n",
       "                                                    text  \\\n",
       "12848                WEAR A FUCKING MASK YOU STUPID FUCK   \n",
       "20535  Goodnight. Fuck racists. Fuck Ted Cuntface Cru...   \n",
       "235                                 copernicus was wrong   \n",
       "9540                                        My mask ugly   \n",
       "10850  America is full of fools. Weak mask wearing fo...   \n",
       "12092  America is full of fools. Weak mask wearing fo...   \n",
       "17667                            @Coolretro72 Mask fail.   \n",
       "21424                            @Coolretro72 Mask fail.   \n",
       "9083   Oh fuck I missed more than 1 affinity shit bet...   \n",
       "3931                  Also mask to face ratio SUCKS SHIT   \n",
       "\n",
       "                                                entities retweet_count  \\\n",
       "12848  {'hashtags': [], 'symbols': [], 'user_mentions...             0   \n",
       "20535  {'hashtags': [], 'symbols': [], 'user_mentions...             0   \n",
       "235    {'hashtags': [], 'symbols': [], 'user_mentions...             0   \n",
       "9540   {'hashtags': [], 'symbols': [], 'user_mentions...             0   \n",
       "10850  {'hashtags': [], 'symbols': [], 'user_mentions...             1   \n",
       "12092  {'hashtags': [], 'symbols': [], 'user_mentions...             2   \n",
       "17667  {'hashtags': [], 'symbols': [], 'user_mentions...             0   \n",
       "21424  {'hashtags': [], 'symbols': [], 'user_mentions...             0   \n",
       "9083   {'hashtags': [], 'symbols': [], 'user_mentions...             0   \n",
       "3931   {'hashtags': [], 'symbols': [], 'user_mentions...             0   \n",
       "\n",
       "      favorite_count           created_at  WC Analytic  ... Quote Apostro  \\\n",
       "12848              0  2021-02-21 02:59:35   7    93.26  ...   0.0     0.0   \n",
       "20535              0  2021-02-21 05:58:21  11    98.34  ...   0.0     0.0   \n",
       "235                0  2021-02-14 06:30:15   3    18.82  ...   0.0     0.0   \n",
       "9540               0  2021-02-21 01:57:06   3    18.82  ...   0.0     0.0   \n",
       "10850              6  2021-02-21 02:39:01   9    93.26  ...   0.0     0.0   \n",
       "12092             11  2021-02-21 02:39:01   9    93.26  ...   0.0     0.0   \n",
       "17667              0  2021-02-21 05:03:28   3    93.26  ...   0.0     0.0   \n",
       "21424              1  2021-02-21 05:03:28   3    93.26  ...   0.0     0.0   \n",
       "9083               0  2021-02-21 02:09:11  17    93.26  ...   0.0     0.0   \n",
       "3931               5  2021-02-21 00:26:37   7    68.29  ...   0.0     0.0   \n",
       "\n",
       "      Parenth OtherP  Unnamed: 101  Unnamed: 102  Unnamed: 103  Unnamed: 104  \\\n",
       "12848     0.0   0.00           NaN           NaN           NaN           NaN   \n",
       "20535     0.0   0.00           NaN           NaN           NaN           NaN   \n",
       "235       0.0   0.00           NaN           NaN           NaN           NaN   \n",
       "9540      0.0   0.00           NaN           NaN           NaN           NaN   \n",
       "10850     0.0   0.00           NaN           NaN           NaN           NaN   \n",
       "12092     0.0   0.00           NaN           NaN           NaN           NaN   \n",
       "17667     0.0  33.33           NaN           NaN           NaN           NaN   \n",
       "21424     0.0  33.33           NaN           NaN           NaN           NaN   \n",
       "9083      0.0   0.00           NaN           NaN           NaN           NaN   \n",
       "3931      0.0   0.00           NaN           NaN           NaN           NaN   \n",
       "\n",
       "       Unnamed: 105  Unnamed: 106  \n",
       "12848           NaN           NaN  \n",
       "20535           NaN           NaN  \n",
       "235             NaN           NaN  \n",
       "9540            NaN           NaN  \n",
       "10850           NaN           NaN  \n",
       "12092           NaN           NaN  \n",
       "17667           NaN           NaN  \n",
       "21424           NaN           NaN  \n",
       "9083            NaN           NaN  \n",
       "3931            NaN           NaN  \n",
       "\n",
       "[10 rows x 107 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.nlargest(10, ['negemo'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immediate-continent",
   "metadata": {},
   "source": [
    "A similar situation happens. We can see that some of these tweets have negative emotions over the fact not enough people are wearing masks while others have negative emotions *because* of masks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agricultural-information",
   "metadata": {},
   "source": [
    "## Credit Listing\n",
    "\n",
    "**Lipsa Jena**\n",
    "* asd\n",
    "\n",
    "**Ji Kang**\n",
    "* Collected past twitter using the IEEE and Kaggle tweet-id datasets\n",
    "* Ran data through LIWC to generate LIWC metrics.\n",
    "\n",
    "**Yuanfeng Li**\n",
    "* asd\n",
    "\n",
    "**Yu Ling**\n",
    "* asd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "representative-guinea",
   "metadata": {},
   "source": [
    "## Report format using QQQ\n",
    "\n",
    "1. Qualitative\n",
    "* Question, problem, hypothesis, claim, context, motivation\n",
    "* Definitions, data, methods to be used\n",
    "* Rationale, assumptions, biases\n",
    "\n",
    "2. Quantitative:\n",
    "* Data processing, analysis, visualization\n",
    "* Documented code and results\n",
    "* Summary visuals\n",
    "\n",
    "3. Qualitative:\n",
    "* Answer, update question/claim, summary, re-contextualization, story, * relate to domain knowledge\n",
    "* Uncertainty, limitations, caveats\n",
    "* New problems, next steps\n",
    "\n",
    "4. Repeat. QQQ-QQQ-QQQ-...\n",
    "* Break down a large problem into parts\n",
    "* Alternative approaches to a problem\n",
    "* Sequence of related pro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limited-encounter",
   "metadata": {},
   "source": [
    "## References: \n",
    "* Good example of a Jupyter Notebook report: https://nbviewer.jupyter.org/gist/nealcaren/5105037\n",
    "(https://nbviewer.jupyter.org/gist/nealcaren/5105037)\n",
    "\n",
    "* QQQ: https://www.bava.stat.vt.edu/wp-content/uploads/2017/08/Developing-a-New-Interdisciplinary-\n",
    "Computational-Analytics-Undergraduate-Program-A-Qualitative-Quantitative-Qualitative-Approach.pdf\n",
    "(https://www.bava.stat.vt.edu/wp-content/uploads/2017/08/Developing-a-New-Interdisciplinary-\n",
    "Computational-Analytics-Undergraduate-Program-A-Qualitative-Quantitative-Qualitative-Approach.pdf)\n",
    "\n",
    "* Using visuals to support claims: https://www.cbre.com/research-and-reports/Scoring-Tech-Talent-in-North-\n",
    "America-2018 (https://www.cbre.com/research-and-reports/Scoring-Tech-Talent-in-North-America-2018)\n",
    "\n",
    "* Typical industry spam: https://www.seagate.com/files/www-content/our-story/trends/files/idc-seagate-\n",
    "dataage-whitepaper.pdf (https://www.seagate.com/files/www-content/our-story/trends/files/idc-seagate-\n",
    "dataage-whitepaper.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
